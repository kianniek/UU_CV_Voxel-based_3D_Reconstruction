{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_text",
   "metadata": {},
   "source": [
    "# Volumetric Reconstruction Pipeline\n",
    "\n",
    "### Dependencies\n",
    "* OpenCV, NumPy, Matplotlib\n",
    "* Data directory structure: `data/cam1/`, `data/cam2/`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Shared Configuration\n",
    "CAM_IDS = [1, 2, 3, 4]\n",
    "CHECKERBOARD_SIZE = (6, 8)  # Defined in checkerboard.xml\n",
    "SQUARE_SIZE = 25             # mm\n",
    "\n",
    "def get_config_path(cam_id):\n",
    "    return f'data/cam{cam_id}/config.xml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task1_header",
   "metadata": {},
   "source": [
    "## Task 1: Calibration (Kian)\n",
    "Focus: Intrinsics from `intrinsics.avi` and Extrinsics from `checkerboard.avi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task1_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Projects a grid onto the image plane using a perspective transform derived from the corners\n",
    "def project_grid_perspective(four_corners, cols, rows):\n",
    "    src_ideal = np.array([\n",
    "        [0, 0], [cols-1, 0], [cols-1, rows-1], [0, rows-1]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    dst_current = np.array(four_corners, dtype=np.float32)\n",
    "    H_matrix = cv2.getPerspectiveTransform(src_ideal, dst_current)\n",
    "    grid_x, grid_y = np.meshgrid(np.arange(cols), np.arange(rows))\n",
    "    ideal_points = np.vstack([grid_x.ravel(), grid_y.ravel()]).T.astype(np.float32).reshape(-1, 1, 2)\n",
    "    \n",
    "    return cv2.perspectiveTransform(ideal_points, H_matrix)\n",
    "\n",
    "# Warps the image region to a flat view to refine corner detection, then projects points back\n",
    "def refine_corners_via_warping(image_gray, four_corners, cols, rows):\n",
    "    w_top = np.linalg.norm(four_corners[0] - four_corners[1])\n",
    "    w_bot = np.linalg.norm(four_corners[3] - four_corners[2])\n",
    "    h_left = np.linalg.norm(four_corners[0] - four_corners[3])\n",
    "    h_right = np.linalg.norm(four_corners[1] - four_corners[2])\n",
    "    \n",
    "    dst_width = int(max(w_top, w_bot))\n",
    "    dst_height = int(max(h_left, h_right))\n",
    "    padding = 50 \n",
    "    \n",
    "    dst_corners = np.array([\n",
    "        [padding, padding],\n",
    "        [padding + dst_width, padding],\n",
    "        [padding + dst_width, padding + dst_height],\n",
    "        [padding, padding + dst_height]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(np.array(four_corners, dtype=np.float32), dst_corners)\n",
    "    M_inv = np.linalg.inv(M) \n",
    "    warped_image = cv2.warpPerspective(image_gray, M, (dst_width + 2*padding, dst_height + 2*padding))\n",
    "    \n",
    "    grid_x, grid_y = np.meshgrid(\n",
    "        np.linspace(padding, padding + dst_width, cols),\n",
    "        np.linspace(padding, padding + dst_height, rows)\n",
    "    )\n",
    "    \n",
    "    warped_guesses = np.vstack([grid_x.ravel(), grid_y.ravel()]).T.astype(np.float32)\n",
    "    warped_guesses = np.ascontiguousarray(warped_guesses).reshape(-1, 1, 2)\n",
    "    \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 40, 0.001)\n",
    "    refined_warped = cv2.cornerSubPix(warped_image, warped_guesses, (5, 5), (-1, -1), criteria)\n",
    "    \n",
    "    return cv2.perspectiveTransform(refined_warped, M_inv)\n",
    "\n",
    "# Interactive GUI with Magnifying Glass to allow users to move 4 corners\n",
    "def select_corners_interface(image_gray, cols, rows, initial_handles=None):\n",
    "    CLICK_SENSITIVITY = 20\n",
    "    HANDLE_RADIUS = 1\n",
    "    GRID_RADIUS = 1\n",
    "    \n",
    "    height, width = image_gray.shape\n",
    "    \n",
    "    if initial_handles is not None:\n",
    "        handles = [np.array(pt, dtype=np.float32) for pt in initial_handles]\n",
    "    else:\n",
    "        margin_horizontal, margin_vertical = width // 4, height // 4\n",
    "        handles = [\n",
    "            np.array([margin_horizontal, margin_vertical], dtype=np.float32),\n",
    "            np.array([width - margin_horizontal, margin_vertical], dtype=np.float32),\n",
    "            np.array([width - margin_horizontal, height - margin_vertical], dtype=np.float32),\n",
    "            np.array([margin_horizontal, height - margin_vertical], dtype=np.float32)\n",
    "        ]\n",
    "    \n",
    "    state = {\n",
    "        \"drag_index\": None,\n",
    "        \"mouse_pos\": (width // 2, height // 2),\n",
    "        \"handles\": handles\n",
    "    }\n",
    "    \n",
    "    window_name = \"Manual Calibration - Drag corners. Press 'c' to confirm\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(window_name, 1080, int(1080 * (height/width)))\n",
    "\n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        state[\"mouse_pos\"] = (x, y)\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            for idx, pt in enumerate(state[\"handles\"]):\n",
    "                if np.linalg.norm(pt - [x, y]) < CLICK_SENSITIVITY:\n",
    "                    state[\"drag_index\"] = idx\n",
    "                    break\n",
    "        elif event == cv2.EVENT_MOUSEMOVE and state[\"drag_index\"] is not None:\n",
    "            state[\"handles\"][state[\"drag_index\"]] = np.array([x, y], dtype=np.float32)\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            if state[\"drag_index\"] is not None:\n",
    "                corner = np.array([[[x, y]]], dtype=np.float32)\n",
    "                corner = np.ascontiguousarray(corner)\n",
    "                state[\"handles\"][state[\"drag_index\"]] = corner[0, 0]\n",
    "                state[\"drag_index\"] = None\n",
    "\n",
    "    cv2.setMouseCallback(window_name, mouse_callback)\n",
    "    \n",
    "    display_color = cv2.cvtColor(image_gray, cv2.COLOR_GRAY2BGR)\n",
    "    colors = [(0, 0, 255), (255, 0, 0), (0, 255, 0), (0, 255, 255)]\n",
    "    \n",
    "    while True:\n",
    "        temp_img = display_color.copy()\n",
    "        \n",
    "        corner_points = np.array(state[\"handles\"], np.int32).reshape((-1, 1, 2))\n",
    "        cv2.polylines(temp_img, [corner_points], True, (255, 255, 0), 1)\n",
    "        \n",
    "        grid_points = project_grid_perspective(state[\"handles\"], cols, rows)\n",
    "        if grid_points is not None:\n",
    "            for point in grid_points:\n",
    "                cv2.circle(temp_img, tuple(point[0].astype(int)), GRID_RADIUS, (0, 255, 0), -1)\n",
    "                \n",
    "        for idx, point in enumerate(state[\"handles\"]):\n",
    "            cv2.circle(temp_img, tuple(point.astype(int)), HANDLE_RADIUS, colors[idx], -1)\n",
    "            \n",
    "        mouse_x = np.clip(state[\"mouse_pos\"][0], 0, width - 1)\n",
    "        mouse_y = np.clip(state[\"mouse_pos\"][1], 0, height - 1)\n",
    "        pad_size = 30\n",
    "        \n",
    "        pad_img = cv2.copyMakeBorder(temp_img, pad_size, pad_size, pad_size, pad_size, cv2.BORDER_REPLICATE)\n",
    "        cx, cy = mouse_x + pad_size, mouse_y + pad_size\n",
    "        patch = pad_img[cy-pad_size:cy+pad_size, cx-pad_size:cx+pad_size]\n",
    "        \n",
    "        zoom_size = pad_size * 4\n",
    "        patch_zoomed = cv2.resize(patch, (zoom_size, zoom_size), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        cv2.line(patch_zoomed, (zoom_size//2, 0), (zoom_size//2, zoom_size), (255, 255, 255), 1)\n",
    "        cv2.line(patch_zoomed, (0, zoom_size//2), (zoom_size, zoom_size//2), (255, 255, 255), 1)\n",
    "        cv2.rectangle(patch_zoomed, (0,0), (zoom_size-1, zoom_size-1), (255, 255, 255), 2)\n",
    "        \n",
    "        if mouse_x > width - zoom_size - 20 and mouse_y < zoom_size + 20:\n",
    "            temp_img[10:10+zoom_size, 10:10+zoom_size] = patch_zoomed\n",
    "        else:\n",
    "            temp_img[10:10+zoom_size, width-zoom_size-10:width-10] = patch_zoomed\n",
    "\n",
    "        cv2.imshow(window_name, temp_img)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('c'):\n",
    "            try:\n",
    "                refined_corner_points = refine_corners_via_warping(image_gray, state[\"handles\"], cols, rows)\n",
    "                cv2.destroyWindow(window_name)\n",
    "                return refined_corner_points, np.array(state[\"handles\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Refinement failed: {e}\")\n",
    "                \n",
    "# Calibrate camera intrinsics using intrinsics.avi and checkerboard.xml.\n",
    "def calibrate_intrinsics(cam_id):\n",
    "    xml_path = \"data/checkerboard.xml\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    cols = int(root.find(\"CheckerBoardWidth\").text)\n",
    "    rows = int(root.find(\"CheckerBoardHeight\").text)\n",
    "    square_size = float(root.find(\"CheckerBoardSquareSize\").text)\n",
    "\n",
    "    object_points = np.zeros((rows * cols, 3), np.float32)\n",
    "    object_points[:, :2] = np.mgrid[0:cols, 0:rows].T.reshape(-1, 2)\n",
    "    object_points *= square_size\n",
    "\n",
    "    video_path = f\"data/cam{cam_id}/intrinsics.avi\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    step = max(1, frame_count // 10)\n",
    "    \n",
    "    for i in range(0, frame_count, step):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        found, corners = cv2.findChessboardCorners(gray, (cols, rows), None)\n",
    "        if found:\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "            objpoints.append(object_points)\n",
    "            imgpoints.append(corners2)\n",
    "            \n",
    "    cap.release()\n",
    "    if len(objpoints) < 3:\n",
    "        raise RuntimeError(\"Not enough valid frames for calibration.\")\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    return mtx, dist    \n",
    "\n",
    "# Calibrate camera extrinsics using checkerboard.avi and manual corner selection.\n",
    "def calibrate_extrinsics(cam_id, mtx, dist):\n",
    "    xml_path = \"data/checkerboard.xml\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    cols = int(root.find(\"CheckerBoardWidth\").text)\n",
    "    rows = int(root.find(\"CheckerBoardHeight\").text)\n",
    "    square_size = float(root.find(\"CheckerBoardSquareSize\").text)\n",
    "\n",
    "    object_points = np.zeros((rows * cols, 3), np.float32)\n",
    "    object_points[:, :2] = np.mgrid[0:cols, 0:rows].T.reshape(-1, 2)\n",
    "    object_points *= square_size\n",
    "    \n",
    "    initial_handles = None\n",
    "    config_path = get_config_path(cam_id)\n",
    "    if os.path.exists(config_path):\n",
    "        fs_read = cv2.FileStorage(config_path, cv2.FILE_STORAGE_READ)\n",
    "        corner_node = fs_read.getNode(\"manual_corners\")\n",
    "        if not corner_node.empty():\n",
    "            initial_handles = corner_node.mat()\n",
    "        fs_read.release()\n",
    "\n",
    "    video_path = f\"data/cam{cam_id}/checkerboard.avi\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count // 2)\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        raise RuntimeError(f\"Could not read checkerboard frame for Cam {cam_id}.\")\n",
    "        \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"--- Extrinsic Calibration: Camera {cam_id} ---\")\n",
    "    \n",
    "    corners2d, handles = select_corners_interface(gray, cols, rows, initial_handles)\n",
    "    \n",
    "    ret, rvec, tvec = cv2.solvePnP(object_points, corners2d, mtx, dist)\n",
    "    return rvec, tvec, handles\n",
    "\n",
    "# Saves all calibration parameters to an XML file for future use\n",
    "def save_all_params(cam_id, mtx, dist, rvec, tvec, manual_corners):\n",
    "    fs = cv2.FileStorage(get_config_path(cam_id), cv2.FILE_STORAGE_WRITE)\n",
    "    fs.write(\"camera_matrix\", mtx)\n",
    "    fs.write(\"distortion_coefficients\", dist)\n",
    "    fs.write(\"rotation_vector\", rvec)\n",
    "    fs.write(\"translation_vector\", tvec)\n",
    "    fs.write(\"manual_corners\", manual_corners)\n",
    "    fs.release()\n",
    "\n",
    "# Projects the world origin using matching intrinsics and extrinsics.\n",
    "def visualize_checkerboard_start(cam_id, mtx, dist, rvec, tvec):\n",
    "    xml_path = \"data/checkerboard.xml\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    square_size = float(root.find(\"CheckerBoardSquareSize\").text)\n",
    "    axis_length = square_size * 3\n",
    "    axis_points = np.float32([\n",
    "        [0, 0, 0],\n",
    "        [axis_length, 0, 0],\n",
    "        [0, axis_length, 0],\n",
    "        [0, 0, -axis_length]\n",
    "    ])\n",
    "    axis_colors = [(0, 0, 255), (0, 255, 0), (255, 0, 0)]\n",
    "    \n",
    "    imgpts, _ = cv2.projectPoints(axis_points, rvec, tvec, mtx, dist)\n",
    "    imgpts = imgpts.reshape(-1, 2).astype(int)\n",
    "\n",
    "    video_path = f\"data/cam{cam_id}/checkerboard.avi\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 5) \n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if ret:\n",
    "        origin = tuple(imgpts[0])\n",
    "        pt_x = tuple(imgpts[1])\n",
    "        pt_y = tuple(imgpts[2])\n",
    "        pt_z = tuple(imgpts[3])\n",
    "        \n",
    "        cv2.line(frame, origin, pt_x, axis_colors[0], 2)\n",
    "        cv2.line(frame, origin, pt_y, axis_colors[1], 2)\n",
    "        cv2.line(frame, origin, pt_z, axis_colors[2], 2)\n",
    "        \n",
    "        cv2.circle(frame, origin, 3, (255, 255, 255), -1)\n",
    "        \n",
    "        cv2.imshow(f\"Camera {cam_id} Axes\", frame)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(f\"Error: Could not load frame for Camera {cam_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task2_header",
   "metadata": {},
   "source": [
    "## Task 2: Background Subtraction (Vinn)\n",
    "Focus: HSV thresholding and morphology on `background.avi` and `video.avi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "task2_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_background_model(cam_id):\n",
    "    # TODO: Average frames or use Gaussian mixture\n",
    "    pass\n",
    "\n",
    "def get_foreground_mask(frame, bg_model, thresholds):\n",
    "    # TODO: BGR to HSV -> Diff -> Threshold -> Erode/Dilate\n",
    "    return mask\n",
    "\n",
    "# CHOICE 2: Automated thresholding function\n",
    "def optimize_thresholds(frame, manual_segmentation):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task3_header",
   "metadata": {},
   "source": [
    "## Task 3: Voxel Reconstruction (Combined)\n",
    "Focus: 3D back-projection and lookup tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "task3_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lookup_table(cam_configs, step=10):\n",
    "    # Programmer A: cv2.projectPoints for voxel grid\n",
    "    pass\n",
    "\n",
    "def reconstruct_voxels(masks, lookup_table):\n",
    "    # Programmer A/B: Logical AND of all camera masks\n",
    "    pass\n",
    "\n",
    "# CHOICE 3: Voxel Coloring\n",
    "# CHOICE 4: Marching Cubes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "execution_header",
   "metadata": {},
   "source": [
    "## Main Pipeline Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main_loop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Extrinsic Calibration: Camera 1 ---\n",
      "Visualizing Origin for Camera 1...\n",
      "--- Extrinsic Calibration: Camera 2 ---\n",
      "Visualizing Origin for Camera 2...\n",
      "--- Extrinsic Calibration: Camera 3 ---\n",
      "Visualizing Origin for Camera 3...\n",
      "--- Extrinsic Calibration: Camera 4 ---\n",
      "Visualizing Origin for Camera 4...\n",
      "Pipeline Initialized\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1. Run Calibration (Cell 2)\n",
    "    for cam_id in CAM_IDS:\n",
    "        mtx, dist = calibrate_intrinsics(cam_id)\n",
    "        rvec, tvec, handles = calibrate_extrinsics(cam_id, mtx, dist)\n",
    "        save_all_params(cam_id, mtx, dist, rvec, tvec, handles)\n",
    "        print(f\"Visualizing Origin for Camera {cam_id}...\")\n",
    "        visualize_checkerboard_start(cam_id, mtx, dist, rvec, tvec)\n",
    "    # 2. Build BG Models (B)\n",
    "    # 3. Create LUT (A)\n",
    "    # 4. Process Video frames and render 3D (A&B)\n",
    "    print(\"Pipeline Initialized\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
